URL : https://3months.tistory.com/566

R과 python pandas 는 in-memory 처리 방식이다. 모든 데이터를 메모리에 적재한 후, 처리한다.
만약 램이 8GB 인 머신을 사용한다고 하면, 이러한 데이터들을 로드조차 하지 못하고, out-of-memory 에러로 커널이 죽는 모습을 확인할 수 있게 된다
pyspark 환경에서는 메모리 사용량을 최소화하는 방식으로 용량이 크고, 포맷이 다양한 데이터들을 "특정 데이터 구조" 로 로드하고 처리하는 것이 가능.
즉, pyspark 는 시간 및 컴퓨팅 자원 측면에서 효율적으로 데이터 처리/분석을 할 수 있도록 도와준다

pyspark 와 pandas 의 큰 차이점 중 하나는 pyspark 는 lazy 하고, pandas 는 eager 하다는 것.
pyspark 에서는 실제 결과가 필요할 때까지 실행을 유보한다 (lazy evaluation)
-> 전체 데이터를 메모리에 저장하지 않아도 되기 때문에, 효율적으로 데이터를 처리할 수 있다

pandas 에서는 함수가 호출되는 즉시 실행되며 (eager evaluation)
모든 것은 메모리에 저장된다. pyspark 환경에서의 데이터 처리를 한다고 했을 때,
eager operation 은 사용하는 것은 지양하는 것이, 리소스 절감 측면에서 바람직하다